{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "HUagNiZ3QgMI",
    "outputId": "4eb3c298-5fa8-43ad-97c7-ba2106a8ec7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eRVBOkzMQgMO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LAy2Oi--QgMR"
   },
   "outputs": [],
   "source": [
    "# Activities are the class labels\n",
    "# It is a 6 class classification\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "# Utility function to print the confusion matrix\n",
    "def confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])\n",
    "\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aPDjC9mZQgMU"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2UQTC5HVQgMV"
   },
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATADIR = 'gdrive/My Drive/HAR/UCI_HAR_Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5UefDM2GQgMY"
   },
   "outputs": [],
   "source": [
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SwWGaUp6QgMb"
   },
   "outputs": [],
   "source": [
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'gdrive/My Drive/HAR/UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6PZfK0rNQgMd"
   },
   "outputs": [],
   "source": [
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'gdrive/My Drive/HAR/UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0] \n",
    "\n",
    "    return pd.get_dummies(y).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E3OS3n6nQgMh"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9dSyfOQmjXHK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_0QrHNajQgMl"
   },
   "outputs": [],
   "source": [
    "# Importing tensorflow\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EyKaqGULQgMp"
   },
   "outputs": [],
   "source": [
    "# Configuring a session\n",
    "session_conf = tf.ConfigProto(\n",
    "   intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "v9RuwAwfQgMt",
    "outputId": "c37534a8-568e-4b80-de98-856414d73e63"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import Keras\n",
    "from keras import backend as K\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iSFOkVC3QgMy"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B_p7j0BXQgM0"
   },
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "base_epochs = 30\n",
    "base_batch_size = 32\n",
    "base_n_hidden = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbxCdiObQgM3"
   },
   "outputs": [],
   "source": [
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "B4p_rDcSQgM6",
    "outputId": "deb6a263-ce3a-48c5-9d34-02c432e7e18c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Loading the train and test data\n",
    "X_train, X_test, Y_train, Y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wgS4tgpXjl-G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "E6UQpTYMQgM8",
    "outputId": "2de8dccb-0064-4a58-9188-39f94e81c0dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "9\n",
      "7352\n"
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)\n",
    "\n",
    "print(timesteps)\n",
    "print(input_dim)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gyXNn7UKn9UW"
   },
   "source": [
    "<h3>LSTM_ Base_ Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "id": "83hYIvQNlH9m",
    "outputId": "2a2bc6e2-398e-45de-dfb1-aa6bf5a15b60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 64)                18944     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 19,590\n",
      "Trainable params: 19,462\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(base_n_hidden, input_shape=(timesteps, input_dim)))\n",
    "#adding a batch normalization layer \n",
    "model.add(BatchNormalization())\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.4))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "ey_MQ4OxlIC7",
    "outputId": "70d6c98c-1c81-4df2-de29-690936efb9ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='RMSprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "id": "y-oe-z1elIIq",
    "outputId": "30a6ed4e-7ca3-4da7-c1fb-1c46aca80e1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/10\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 1.0304 - acc: 0.5858 - val_loss: 0.7335 - val_acc: 0.7021\n",
      "Epoch 2/10\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.5408 - acc: 0.7896 - val_loss: 0.6607 - val_acc: 0.8008\n",
      "Epoch 3/10\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.3138 - acc: 0.8855 - val_loss: 0.9312 - val_acc: 0.7754\n",
      "Epoch 4/10\n",
      "7352/7352 [==============================] - 59s 8ms/step - loss: 0.2291 - acc: 0.9128 - val_loss: 0.4118 - val_acc: 0.8850\n",
      "Epoch 5/10\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1920 - acc: 0.9297 - val_loss: 0.3271 - val_acc: 0.8924\n",
      "Epoch 6/10\n",
      "7352/7352 [==============================] - 59s 8ms/step - loss: 0.1818 - acc: 0.9346 - val_loss: 0.3125 - val_acc: 0.8938\n",
      "Epoch 7/10\n",
      "7352/7352 [==============================] - 59s 8ms/step - loss: 0.1685 - acc: 0.9387 - val_loss: 0.3015 - val_acc: 0.8843\n",
      "Epoch 8/10\n",
      "7352/7352 [==============================] - 59s 8ms/step - loss: 0.1515 - acc: 0.9429 - val_loss: 0.3354 - val_acc: 0.8921\n",
      "Epoch 9/10\n",
      "7352/7352 [==============================] - 59s 8ms/step - loss: 0.1521 - acc: 0.9388 - val_loss: 0.3122 - val_acc: 0.9226\n",
      "Epoch 10/10\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1487 - acc: 0.9442 - val_loss: 0.2675 - val_acc: 0.9104\n",
      "CPU times: user 11min 1s, sys: 38.8 s, total: 11min 40s\n",
      "Wall time: 10min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe6010ddd68>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=32,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "aGyW7VTXvOx4",
    "outputId": "976df3cb-6747-45a9-e3a2-a243707dff30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2675111037987024\n",
      "Test accuracy: 91.04173736002714\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test,verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_da_HtDUvsS5"
   },
   "outputs": [],
   "source": [
    "#train_data\n",
    "X_train=X_train[:6000]\n",
    "Y_train=Y_train[:6000]\n",
    "#cv_data\n",
    "X_cv=X_train[:1352]\n",
    "Y_cv=Y_train[:1352]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "16RFIwy4YjZ7",
    "outputId": "a6514391-38ec-48be-e165-88057cdac87e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 128, 9) (6000, 6)\n",
      "(1352, 128, 9) (1352, 6)\n",
      "(2947, 128, 9) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_cv.shape,Y_cv.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3t9MPejCmFw1"
   },
   "outputs": [],
   "source": [
    "np.save(\"gdrive/My Drive/HAR/x_train\",X_train)\n",
    "np.save(\"gdrive/My Drive/HAR/y_train\",Y_train)\n",
    "np.save(\"gdrive/My Drive/HAR/x_cv\",X_cv)\n",
    "np.save(\"gdrive/My Drive/HAR/y_cv\",Y_cv)\n",
    "np.save(\"gdrive/My Drive/HAR/x_test\",X_test)\n",
    "np.save(\"gdrive/My Drive/HAR/y_test\",Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zeKa7WRl11oD"
   },
   "outputs": [],
   "source": [
    "X_train=np.load('gdrive/My Drive/HAR/x_train.npy')\n",
    "Y_train=np.load('gdrive/My Drive/HAR/y_train.npy')\n",
    "X_cv=np.load('gdrive/My Drive/HAR/x_cv.npy')\n",
    "Y_cv=np.load('gdrive/My Drive/HAR/y_cv.npy')\n",
    "X_test=np.load('gdrive/My Drive/HAR/x_test.npy')\n",
    "Y_test=np.load('gdrive/My Drive/HAR/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "Ev5Xl3OCnd7R",
    "outputId": "2c18380b-9e76-4968-d91c-3acf24be2b89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================================================================================================\n",
      "for lstm cells 12 train_loss: 0.5427719736178793 train_acc: 0.7983333333333333 cv_loss: 0.5774555450977659 cv_acc: 0.7943786982248521\n",
      "==============================================================================================================================================================\n",
      "==============================================================================================================================================================\n",
      "for lstm cells 36 train_loss: 0.1419026134143011 train_acc: 0.948 cv_loss: 0.1471664534554336 cv_acc: 0.9312130177514792\n",
      "==============================================================================================================================================================\n",
      "==============================================================================================================================================================\n",
      "for lstm cells 64 train_loss: 0.15687254037896248 train_acc: 0.9456666666666667 cv_loss: 0.1529195671973436 cv_acc: 0.9304733727810651\n",
      "==============================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "lstms = [12,36,64]\n",
    "train_lstms_loss = []\n",
    "cv_lstms_loss = []\n",
    "\n",
    "\n",
    "\n",
    "for i in lstms:\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(i, input_shape=(timesteps, input_dim)))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(n_classes, activation='softmax'))\n",
    "  model.compile(loss='categorical_crossentropy',optimizer='RMSprop',metrics=['accuracy'])\n",
    "  model.fit(X_train,Y_train,batch_size=32,validation_data=(X_cv, Y_cv),epochs=10,verbose=0)\n",
    "  train_score = model.evaluate(X_train, Y_train,verbose=0)\n",
    "  train_lstms_loss.append(train_score)\n",
    "  test_score = model.evaluate(X_cv, Y_cv,verbose=0)\n",
    "  cv_lstms_loss.append(test_score)\n",
    "  print(\"==============================================================================================================================================================\")\n",
    "  print(\"for lstm cells\",i,\"train_loss:\",train_score[0],\"train_acc:\",train_score[1],\"cv_loss:\",test_score[0],\"cv_acc:\",test_score[1])\n",
    "  print(\"==============================================================================================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "ZZ7zMGBOpkuc",
    "outputId": "869b61a0-3b16-4f0b-dabd-d59a6d880bc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================================\n",
      "for dropout 0.2 train_loss: 0.09121699480417676 train_acc: 0.9618333333333333 cv_loss: 0.08054623748949032 cv_acc: 0.9556213017751479\n",
      "========================================================================================================================================\n",
      "========================================================================================================================================\n",
      "for dropout 0.4 train_loss: 0.2927109430801174 train_acc: 0.9185 cv_loss: 0.22138404586332894 cv_acc: 0.9408284023668639\n",
      "========================================================================================================================================\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "========================================================================================================================================\n",
      "for dropout 0.6 train_loss: 0.2663697602033571 train_acc: 0.9165 cv_loss: 0.2898362064807076 cv_acc: 0.915680473372781\n",
      "========================================================================================================================================\n",
      "WARNING:tensorflow:Large dropout rate: 0.9 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "========================================================================================================================================\n",
      "for dropout 0.9 train_loss: 0.4850111870571758 train_acc: 0.8276666666666667 cv_loss: 0.42911438657158224 cv_acc: 0.8461538461538461\n",
      "========================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "train_dropout_loss = []\n",
    "cv_dropout_loss = []\n",
    "dropouts = [0.2,0.4,0.6,0.9]\n",
    "\n",
    "for i in dropouts:\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(64, input_shape=(timesteps, input_dim)))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dropout(i))\n",
    "  model.add(Dense(n_classes, activation='softmax'))\n",
    "  model.compile(loss='categorical_crossentropy',optimizer='RMSprop',metrics=['accuracy'])\n",
    "  model.fit(X_train,Y_train,batch_size=32,validation_data=(X_cv, Y_cv),epochs=10,verbose=0)\n",
    "  train_score = model.evaluate(X_train, Y_train,verbose=0)\n",
    "  train_dropout_loss.append(train_score[0])\n",
    "  test_score = model.evaluate(X_cv, Y_cv,verbose=0)\n",
    "  cv_dropout_loss.append(test_score[0])\n",
    "  print(\"========================================================================================================================================\")\n",
    "  print(\"for dropout\",i,\"train_loss:\",train_score[0],\"train_acc:\",train_score[1],\"cv_loss:\",test_score[0],\"cv_acc:\",test_score[1])\n",
    "  print(\"========================================================================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "A_Gz4cR0-Ycy",
    "outputId": "14290c16-af2d-41c8-d86f-65fecff65a3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================================\n",
      "for optimizer  RMSprop train_loss: 0.09372042466270614 train_acc: 0.9646666666666667 cv_loss: 0.08798773764093963 cv_acc: 0.9563609467455622\n",
      "========================================================================================================================================\n",
      "========================================================================================================================================\n",
      "for optimizer  Adadelta train_loss: 0.10666192313204859 train_acc: 0.9461666666666667 cv_loss: 0.0923617873280571 cv_acc: 0.9571005917159763\n",
      "========================================================================================================================================\n",
      "========================================================================================================================================\n",
      "for optimizer  Adam train_loss: 0.09250945657089081 train_acc: 0.9641666666666666 cv_loss: 0.08666882475565281 cv_acc: 0.9548816568047337\n",
      "========================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "train_opt_loss = []\n",
    "cv_opt_loss = []\n",
    "optimizers = ['RMSprop','Adadelta','Adam']\n",
    "\n",
    "for i in optimizers:\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(64, input_shape=(timesteps, input_dim)))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(n_classes, activation='softmax'))\n",
    "  model.compile(loss='categorical_crossentropy',optimizer=i,metrics=['accuracy'])\n",
    "  model.fit(X_train,Y_train,batch_size=32,validation_data=(X_cv, Y_cv),epochs=10,verbose=0)\n",
    "  train_score = model.evaluate(X_train, Y_train,verbose=0)\n",
    "  train_opt_loss.append(train_score[0])\n",
    "  test_score = model.evaluate(X_cv, Y_cv,verbose=0)\n",
    "  cv_opt_loss.append(test_score[0])\n",
    "  print(\"========================================================================================================================================\")\n",
    "  print(\"for optimizer \",i,\"train_loss:\",train_score[0],\"train_acc:\",train_score[1],\"cv_loss:\",test_score[0],\"cv_acc:\",test_score[1])\n",
    "  print(\"========================================================================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "id": "E7dfxAVpiRhb",
    "outputId": "76feb2e1-f263-497d-e144-5668881da267"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 2947 samples\n",
      "Epoch 1/20\n",
      "6000/6000 [==============================] - 57s 10ms/step - loss: 0.7780 - acc: 0.6847 - val_loss: 0.9274 - val_acc: 0.7065\n",
      "Epoch 2/20\n",
      "6000/6000 [==============================] - 48s 8ms/step - loss: 0.4287 - acc: 0.8255 - val_loss: 1.0003 - val_acc: 0.6176\n",
      "Epoch 3/20\n",
      "6000/6000 [==============================] - 49s 8ms/step - loss: 0.2508 - acc: 0.9037 - val_loss: 0.4645 - val_acc: 0.8490\n",
      "Epoch 4/20\n",
      "6000/6000 [==============================] - 49s 8ms/step - loss: 0.1943 - acc: 0.9327 - val_loss: 1.4064 - val_acc: 0.7598\n",
      "Epoch 5/20\n",
      "6000/6000 [==============================] - 49s 8ms/step - loss: 0.1708 - acc: 0.9363 - val_loss: 0.2106 - val_acc: 0.9179\n",
      "Epoch 6/20\n",
      "6000/6000 [==============================] - 49s 8ms/step - loss: 0.1470 - acc: 0.9448 - val_loss: 0.2387 - val_acc: 0.9223\n",
      "Epoch 7/20\n",
      "6000/6000 [==============================] - 48s 8ms/step - loss: 0.1351 - acc: 0.9467 - val_loss: 0.3111 - val_acc: 0.9026\n",
      "Epoch 8/20\n",
      "6000/6000 [==============================] - 48s 8ms/step - loss: 0.1339 - acc: 0.9485 - val_loss: 0.3288 - val_acc: 0.9118\n",
      "Epoch 9/20\n",
      "6000/6000 [==============================] - 49s 8ms/step - loss: 0.1201 - acc: 0.9497 - val_loss: 0.3280 - val_acc: 0.9148\n",
      "Epoch 10/20\n",
      "6000/6000 [==============================] - 49s 8ms/step - loss: 0.1259 - acc: 0.9535 - val_loss: 0.3860 - val_acc: 0.9063\n",
      "Epoch 11/20\n",
      "6000/6000 [==============================] - 49s 8ms/step - loss: 0.1137 - acc: 0.9552 - val_loss: 0.4017 - val_acc: 0.9043\n",
      "Epoch 12/20\n",
      "6000/6000 [==============================] - 49s 8ms/step - loss: 0.1108 - acc: 0.9550 - val_loss: 0.3834 - val_acc: 0.9162\n",
      "Epoch 13/20\n",
      "6000/6000 [==============================] - 49s 8ms/step - loss: 0.1060 - acc: 0.9552 - val_loss: 0.3190 - val_acc: 0.9077\n",
      "Epoch 14/20\n",
      "6000/6000 [==============================] - 49s 8ms/step - loss: 0.1076 - acc: 0.9545 - val_loss: 0.3842 - val_acc: 0.9135\n",
      "Epoch 15/20\n",
      "6000/6000 [==============================] - 49s 8ms/step - loss: 0.1084 - acc: 0.9550 - val_loss: 0.4441 - val_acc: 0.9080\n",
      "Epoch 16/20\n",
      "6000/6000 [==============================] - 49s 8ms/step - loss: 0.1154 - acc: 0.9558 - val_loss: 0.4180 - val_acc: 0.9026\n",
      "Epoch 17/20\n",
      "6000/6000 [==============================] - 49s 8ms/step - loss: 0.1126 - acc: 0.9558 - val_loss: 0.4901 - val_acc: 0.8996\n",
      "Epoch 18/20\n",
      "6000/6000 [==============================] - 50s 8ms/step - loss: 0.1067 - acc: 0.9577 - val_loss: 0.4419 - val_acc: 0.9077\n",
      "Epoch 19/20\n",
      "6000/6000 [==============================] - 50s 8ms/step - loss: 0.1005 - acc: 0.9565 - val_loss: 0.7073 - val_acc: 0.8941\n",
      "Epoch 20/20\n",
      "6000/6000 [==============================] - 50s 8ms/step - loss: 0.1034 - acc: 0.9562 - val_loss: 0.3852 - val_acc: 0.9145\n",
      "Test loss: 0.38519705226556006\n",
      "Test accuracy: 91.44893111638956\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(timesteps, input_dim)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='RMSprop',metrics=['accuracy'])\n",
    "model.fit(X_train,Y_train,batch_size=32,validation_data=(X_test, Y_test),epochs=20,verbose=1)\n",
    "score = model.evaluate(X_test, Y_test,verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "colab_type": "code",
    "id": "MVldI3Gku_UJ",
    "outputId": "a35b3036-8cfe-4fbc-c4cc-05f989dc58f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples, validate on 2947 samples\n",
      "Epoch 1/20\n",
      "6000/6000 [==============================] - 107s 18ms/step - loss: 0.4946 - acc: 0.8167 - val_loss: 1.9998 - val_acc: 0.6179\n",
      "Epoch 2/20\n",
      "6000/6000 [==============================] - 98s 16ms/step - loss: 0.1874 - acc: 0.9323 - val_loss: 0.5322 - val_acc: 0.8768\n",
      "Epoch 3/20\n",
      "6000/6000 [==============================] - 98s 16ms/step - loss: 0.1426 - acc: 0.9450 - val_loss: 0.4220 - val_acc: 0.8938\n",
      "Epoch 4/20\n",
      "6000/6000 [==============================] - 97s 16ms/step - loss: 0.1465 - acc: 0.9477 - val_loss: 0.2921 - val_acc: 0.9189\n",
      "Epoch 5/20\n",
      "6000/6000 [==============================] - 97s 16ms/step - loss: 0.1209 - acc: 0.9503 - val_loss: 0.3555 - val_acc: 0.9006\n",
      "Epoch 6/20\n",
      "6000/6000 [==============================] - 98s 16ms/step - loss: 0.1279 - acc: 0.9492 - val_loss: 0.4008 - val_acc: 0.9006\n",
      "Epoch 7/20\n",
      "6000/6000 [==============================] - 98s 16ms/step - loss: 0.1165 - acc: 0.9545 - val_loss: 0.4223 - val_acc: 0.9135\n",
      "Epoch 8/20\n",
      "6000/6000 [==============================] - 97s 16ms/step - loss: 0.1215 - acc: 0.9515 - val_loss: 0.4944 - val_acc: 0.9121\n",
      "Epoch 9/20\n",
      "6000/6000 [==============================] - 98s 16ms/step - loss: 0.1096 - acc: 0.9523 - val_loss: 0.3731 - val_acc: 0.9152\n",
      "Epoch 10/20\n",
      "6000/6000 [==============================] - 95s 16ms/step - loss: 0.1260 - acc: 0.9508 - val_loss: 0.2140 - val_acc: 0.9325\n",
      "Epoch 11/20\n",
      "6000/6000 [==============================] - 96s 16ms/step - loss: 0.1070 - acc: 0.9530 - val_loss: 0.4739 - val_acc: 0.9097\n",
      "Epoch 12/20\n",
      "6000/6000 [==============================] - 97s 16ms/step - loss: 0.1110 - acc: 0.9533 - val_loss: 0.9212 - val_acc: 0.8378\n",
      "Epoch 13/20\n",
      "6000/6000 [==============================] - 97s 16ms/step - loss: 0.1084 - acc: 0.9577 - val_loss: 0.2648 - val_acc: 0.9063\n",
      "Epoch 14/20\n",
      "6000/6000 [==============================] - 97s 16ms/step - loss: 0.1055 - acc: 0.9533 - val_loss: 0.6211 - val_acc: 0.8714\n",
      "Epoch 15/20\n",
      "6000/6000 [==============================] - 98s 16ms/step - loss: 0.1054 - acc: 0.9553 - val_loss: 0.3850 - val_acc: 0.9002\n",
      "Epoch 16/20\n",
      "6000/6000 [==============================] - 96s 16ms/step - loss: 0.1110 - acc: 0.9538 - val_loss: 0.3388 - val_acc: 0.9196\n",
      "Epoch 17/20\n",
      "6000/6000 [==============================] - 97s 16ms/step - loss: 0.1026 - acc: 0.9537 - val_loss: 0.2729 - val_acc: 0.9084\n",
      "Epoch 18/20\n",
      "6000/6000 [==============================] - 97s 16ms/step - loss: 0.1027 - acc: 0.9552 - val_loss: 0.2615 - val_acc: 0.9203\n",
      "Epoch 19/20\n",
      "6000/6000 [==============================] - 97s 16ms/step - loss: 0.1111 - acc: 0.9508 - val_loss: 0.2883 - val_acc: 0.9080\n",
      "Epoch 20/20\n",
      "6000/6000 [==============================] - 95s 16ms/step - loss: 0.1073 - acc: 0.9550 - val_loss: 0.2172 - val_acc: 0.9369\n",
      "Test loss: 0.21721666411171675\n",
      "Test accuracy: 93.68849677638276\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(timesteps, input_dim),return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='RMSprop',metrics=['accuracy'])\n",
    "model.fit(X_train,Y_train,batch_size=32,validation_data=(X_test, Y_test),epochs=20,verbose=1)\n",
    "score = model.evaluate(X_test, Y_test,verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I0W9hzMB1Izu"
   },
   "source": [
    "1.By using LSTM 2 layer architecture we got 93% model accuracy so by refering this paper we use a divide and conquer apporach to get some more accuracy than LSTM models Refer: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5949027/\n",
    "\n",
    "2.So we splitting the data into 2 models one model contains 3 class labels and another contains another 3 class labels like 'STANDING,SITTING,LYING' consider as one model called static model and 'WALKING UPSTSAIRS,WALKING DOWNSTAIRS,WALKING' as another model called dynamic model \n",
    "\n",
    "3.First we create a binary  model i.e.., we set >3 class labels  as 1 and < 3 class labels as 0 \n",
    "\n",
    "4.second we create a model for > 3 class labels and predict  also called as static model \n",
    "\n",
    "5.Third we create a model for < 3 class labels and predict also called as dynamic model \n",
    "\n",
    "Refer the above paper for to get some more better understading the way of implementation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZDajsXLxZibZ"
   },
   "source": [
    "<h3> Binary model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "vZWg9PDA4yAD",
    "outputId": "fc957b3e-8636-47e1-ffa2-ef129e0c2476"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/UdiBhaskar/Human-Activity-Recognition--Using-Deep-NN/blob/master/Human%20Activity%20Detection-Without%20Verbose%20.ipynb\n",
    "# Data directory\n",
    "DATADIR = 'gdrive/My Drive/HAR/UCI_HAR_Dataset'\n",
    "\n",
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]\n",
    "\n",
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'gdrive/My Drive/HAR/UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))\n",
    "\n",
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'gdrive/My Drive/HAR/UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "    y[y<=3] = 0 #here we scaling y_class labels 1,2,3 as 0 \n",
    "    y[y>3] = 1 #here we scaling y_class labels 4,5,6 as 1\n",
    "\n",
    "    return pd.get_dummies(y).as_matrix()\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "  \n",
    "# Loading the train and test data\n",
    "X_train_bin, X_test_bin, Y_train_bin, Y_test_bin = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UZGJQYBcdsSr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4eSTMDCKis2k"
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "R-ekq-Mjg_qB",
    "outputId": "876475c1-f6f7-4a97-d536-10c815ab2c39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 126, 64)           1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 126, 64)           256       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 126, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 124, 32)           6176      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 124, 32)           128       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 124, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 62, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1984)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 3970      \n",
      "=================================================================\n",
      "Total params: 12,322\n",
      "Trainable params: 12,130\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "binary_model = Sequential()\n",
    "binary_model.add(Conv1D(filters=64, kernel_size=3, activation='relu',kernel_initializer='he_uniform',input_shape=(timesteps, input_dim)))\n",
    "binary_model.add(BatchNormalization()) \n",
    "binary_model.add(Dropout(0.5))\n",
    "binary_model.add(Conv1D(filters=32, kernel_size=3, activation='relu',kernel_initializer='he_uniform'))\n",
    "binary_model.add(BatchNormalization())\n",
    "binary_model.add(Dropout(0.5))\n",
    "binary_model.add(MaxPooling1D(pool_size=2))\n",
    "binary_model.add(Flatten())\n",
    "binary_model.add(Dense(2, activation='softmax'))\n",
    "binary_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "CZvkuAvLg_u1",
    "outputId": "3ac70d50-3ce0-466b-d206-0e97d90bfd13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 6s 881us/step - loss: 0.0578 - acc: 0.9808 - val_loss: 0.0087 - val_acc: 0.9986\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 3s 357us/step - loss: 0.0079 - acc: 0.9974 - val_loss: 0.0073 - val_acc: 0.9983\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 3s 354us/step - loss: 0.0058 - acc: 0.9984 - val_loss: 0.0106 - val_acc: 0.9956\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 3s 364us/step - loss: 0.0036 - acc: 0.9990 - val_loss: 0.0030 - val_acc: 0.9990\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 3s 348us/step - loss: 0.0043 - acc: 0.9986 - val_loss: 0.0028 - val_acc: 0.9993\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 3s 359us/step - loss: 0.0010 - acc: 0.9996 - val_loss: 0.0041 - val_acc: 0.9993\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 3s 346us/step - loss: 9.2203e-04 - acc: 0.9997 - val_loss: 0.0017 - val_acc: 0.9997\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 3s 356us/step - loss: 0.0042 - acc: 0.9988 - val_loss: 8.5511e-04 - val_acc: 0.9997\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 3s 358us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 6.8389e-04 - val_acc: 0.9997\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 3s 375us/step - loss: 1.3490e-04 - acc: 1.0000 - val_loss: 9.8621e-04 - val_acc: 0.9997\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 3s 392us/step - loss: 0.0030 - acc: 0.9990 - val_loss: 3.6772e-04 - val_acc: 1.0000\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 3s 374us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 9.7679e-04 - val_acc: 0.9997\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 3s 356us/step - loss: 0.0054 - acc: 0.9993 - val_loss: 0.0021 - val_acc: 0.9993\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 3s 350us/step - loss: 4.5302e-04 - acc: 0.9999 - val_loss: 0.0010 - val_acc: 0.9997\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 3s 355us/step - loss: 3.4219e-04 - acc: 0.9997 - val_loss: 0.0020 - val_acc: 0.9997\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 3s 388us/step - loss: 9.7779e-04 - acc: 0.9997 - val_loss: 0.0014 - val_acc: 0.9997\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 3s 352us/step - loss: 8.1858e-04 - acc: 0.9996 - val_loss: 6.5504e-04 - val_acc: 0.9997\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 3s 357us/step - loss: 0.0121 - acc: 0.9978 - val_loss: 0.0086 - val_acc: 0.9986\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 3s 348us/step - loss: 0.0026 - acc: 0.9993 - val_loss: 0.0115 - val_acc: 0.9980\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 3s 370us/step - loss: 2.2864e-04 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 0.9983\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 3s 372us/step - loss: 8.2877e-04 - acc: 0.9995 - val_loss: 0.0092 - val_acc: 0.9983\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 3s 358us/step - loss: 0.0013 - acc: 0.9995 - val_loss: 0.0095 - val_acc: 0.9986\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 3s 352us/step - loss: 7.6134e-04 - acc: 0.9997 - val_loss: 0.0140 - val_acc: 0.9980\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 3s 369us/step - loss: 6.4754e-04 - acc: 0.9997 - val_loss: 0.0075 - val_acc: 0.9986\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 3s 350us/step - loss: 4.1572e-05 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9980\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 3s 377us/step - loss: 4.3807e-05 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 0.9986\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 3s 355us/step - loss: 6.6887e-05 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 0.9986\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 3s 356us/step - loss: 6.9065e-06 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 0.9990\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 3s 353us/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0046 - val_acc: 0.9990\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 3s 350us/step - loss: 0.0026 - acc: 0.9995 - val_loss: 0.0015 - val_acc: 0.9997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7061515588>"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy']) \n",
    "binary_model.fit(X_train_bin,Y_train_bin, epochs=30, batch_size=32,validation_data=(X_test_bin, Y_test_bin), verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "XQ0fwxneg_zQ",
    "outputId": "19f045cc-a6d3-4fa0-9536-b31ca758f6ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.001487480033914023\n",
      "Test accuracy: 99.9660671869698\n"
     ]
    }
   ],
   "source": [
    "binary_model_score = binary_model.evaluate(X_test_bin,Y_test_bin,verbose=0)\n",
    "print('Test loss:', binary_model_score[0])\n",
    "print('Test accuracy:', binary_model_score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MaCGwgzWyEzw"
   },
   "outputs": [],
   "source": [
    "binary_model.save('gdrive/My Drive/HAR/final_binary_model.m1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VFCJkbFmsRVJ"
   },
   "source": [
    "<h3> sharpening test data </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "ZiDuKb0DsOYP",
    "outputId": "1575f8bb-811d-421d-f2fd-176f47ae2bd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from scipy import ndimage\\ndef sharpen(x_test, sigma, alpha):\\n    r = x_test.shape[0]\\n    c = x_test.shape[1]\\n    d = x_test.shape[2]\\n    container = np.empty((r, c, d))\\n    i = 0\\n\\n    for row in x_test:\\n        test = np.array([row])\\n        blurred = ndimage.gaussian_filter(test, sigma)\\n        sharpened = test + alpha * (test - blurred)\\n        container[i] = sharpened\\n        i = i + 1\\n    return container'"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from scipy import ndimage\n",
    "def sharpen(x_test, sigma, alpha):\n",
    "    r = x_test.shape[0]\n",
    "    c = x_test.shape[1]\n",
    "    d = x_test.shape[2]\n",
    "    container = np.empty((r, c, d))\n",
    "    i = 0\n",
    "\n",
    "    for row in x_test:\n",
    "        test = np.array([row])\n",
    "        blurred = ndimage.gaussian_filter(test, sigma)\n",
    "        sharpened = test + alpha * (test - blurred)\n",
    "        container[i] = sharpened\n",
    "        i = i + 1\n",
    "    return container'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yD8wkOYdX2kx"
   },
   "source": [
    "<h3>Static_Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "6HaDRlJkg_2f",
    "outputId": "257ac243-39f2-465c-ba18-905ae7bc0576"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:51: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "# Data directory\n",
    "DATADIR = 'gdrive/My Drive/HAR/UCI_HAR_Dataset'\n",
    "\n",
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]\n",
    "\n",
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'gdrive/My Drive/HAR/UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))\n",
    "\n",
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'gdrive/My Drive/HAR/UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "    y_subset = y > 3 #taking y_class labels greater than 3 \n",
    "    y = y[y_subset]\n",
    "    return pd.get_dummies(y).as_matrix(),y_subset\n",
    "\n",
    "def load_static_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_train_sub  = load_y('train') \n",
    "    y_test,y_test_sub = load_y('test')\n",
    "    X_train = X_train[y_train_sub]\n",
    "    X_test = X_test[y_test_sub]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "  \n",
    "# Loading the train and test data\n",
    "X_train_static, X_test_static, Y_train_static, Y_test_static = load_static_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "CLFFmTYwJI6Y",
    "outputId": "dcf48642-af18-4406-e90f-3d49f63c9774"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:shape (4067, 128, 9) Y:shape (4067, 3)\n",
      "X:shape (1560, 128, 9) Y:shape (1560, 3)\n"
     ]
    }
   ],
   "source": [
    "print('X:shape',X_train_static.shape,'Y:shape',Y_train_static.shape)\n",
    "#print('X:shape',X_cv_static.shape,'Y:shape',Y_cv_static.shape)\n",
    "print('X:shape',X_test_static.shape,'Y:shape',Y_test_static.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "92bHdS8E6fke"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import keras.utils\n",
    "from keras import utils as np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "lFSj9UN-kB6H",
    "outputId": "394fab2a-f106-4b1a-f750-6980913fb3f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.889599 using {'kernel_size2': 1, 'kernel_size': 7, 'filters2': 26, 'filters': 32, 'dropout_rate2': 0.9, 'dropout_rate': 0.2}\n",
      "CPU times: user 55min, sys: 2min 12s, total: 57min 12s\n",
      "Wall time: 48min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def create_model(filters=1,filters2=1,kernel_size2=1,kernel_size=1,dropout_rate2=0.0,dropout_rate=0.0):\n",
    "  model = Sequential()\n",
    "  model.add(keras.layers.Conv1D(filters=filters, kernel_size=kernel_size,kernel_regularizer=keras.regularizers.l2(0.55), \n",
    "                                activation='relu',kernel_initializer='he_uniform',input_shape=(timesteps, input_dim)))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dropout(dropout_rate))\n",
    "  model.add(keras.layers.Conv1D(filters=filters2, kernel_size=kernel_size2,kernel_regularizer=keras.regularizers.l2(0.28),\n",
    "                                activation='relu',kernel_initializer='he_uniform'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dropout(dropout_rate2))\n",
    "  model.add(MaxPooling1D(pool_size=2))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(3, activation='softmax'))\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy']) \n",
    "  return model\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=30, batch_size=16, verbose=0)\n",
    "# define the grid search parameters \n",
    "filters = [1,32,64]\n",
    "filters2 = [1,26,36]\n",
    "kernel_size = [1,3,5,7]\n",
    "kernel_size2 = [1,2,6,8]\n",
    "dropout_rate = [0.0,0.2,0.4,0.6,0.8]\n",
    "dropout_rate2 = [0.0,0.1,0.3,0.5,0.9]\n",
    "param = dict(filters=filters,kernel_size=kernel_size,dropout_rate=dropout_rate,filters2=filters2,\n",
    "             dropout_rate2=dropout_rate2,kernel_size2=kernel_size2)\n",
    "rand = RandomizedSearchCV(estimator=model,param_distributions=param,cv=3)\n",
    "rand_result = rand.fit(X_train_static, Y_train_static)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (rand_result.best_score_, rand_result.best_params_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6Z25m1wFg_6t",
    "outputId": "14d4d3ed-c789-45e0-e13f-1ce793360b0e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4067 samples, validate on 1560 samples\n",
      "Epoch 1/59\n",
      "4067/4067 [==============================] - 6s 1ms/step - loss: 0.2940 - acc: 0.8788 - val_loss: 0.2683 - val_acc: 0.8910\n",
      "Epoch 2/59\n",
      "4067/4067 [==============================] - 2s 415us/step - loss: 0.2222 - acc: 0.9112 - val_loss: 0.3736 - val_acc: 0.8756\n",
      "Epoch 3/59\n",
      "4067/4067 [==============================] - 2s 404us/step - loss: 0.2306 - acc: 0.9046 - val_loss: 0.3486 - val_acc: 0.8545\n",
      "Epoch 4/59\n",
      "4067/4067 [==============================] - 2s 404us/step - loss: 0.2051 - acc: 0.9115 - val_loss: 0.3071 - val_acc: 0.8750\n",
      "Epoch 5/59\n",
      "4067/4067 [==============================] - 2s 422us/step - loss: 0.2001 - acc: 0.9134 - val_loss: 0.2938 - val_acc: 0.8929\n",
      "Epoch 6/59\n",
      "4067/4067 [==============================] - 2s 396us/step - loss: 0.1903 - acc: 0.9211 - val_loss: 0.2835 - val_acc: 0.9038\n",
      "Epoch 7/59\n",
      "4067/4067 [==============================] - 2s 401us/step - loss: 0.2079 - acc: 0.9122 - val_loss: 0.3417 - val_acc: 0.8776\n",
      "Epoch 8/59\n",
      "4067/4067 [==============================] - 2s 403us/step - loss: 0.1784 - acc: 0.9230 - val_loss: 0.2629 - val_acc: 0.9038\n",
      "Epoch 9/59\n",
      "4067/4067 [==============================] - 2s 399us/step - loss: 0.1901 - acc: 0.9191 - val_loss: 0.2487 - val_acc: 0.9122\n",
      "Epoch 10/59\n",
      "4067/4067 [==============================] - 2s 400us/step - loss: 0.1725 - acc: 0.9235 - val_loss: 0.2527 - val_acc: 0.9135\n",
      "Epoch 11/59\n",
      "4067/4067 [==============================] - 2s 422us/step - loss: 0.1767 - acc: 0.9213 - val_loss: 0.2374 - val_acc: 0.9006\n",
      "Epoch 12/59\n",
      "4067/4067 [==============================] - 2s 428us/step - loss: 0.1789 - acc: 0.9203 - val_loss: 0.3060 - val_acc: 0.8808\n",
      "Epoch 13/59\n",
      "4067/4067 [==============================] - 2s 442us/step - loss: 0.1597 - acc: 0.9277 - val_loss: 0.2390 - val_acc: 0.9147\n",
      "Epoch 14/59\n",
      "4067/4067 [==============================] - 2s 424us/step - loss: 0.1491 - acc: 0.9363 - val_loss: 0.3087 - val_acc: 0.9103\n",
      "Epoch 15/59\n",
      "4067/4067 [==============================] - 2s 418us/step - loss: 0.1483 - acc: 0.9361 - val_loss: 0.4047 - val_acc: 0.8910\n",
      "Epoch 16/59\n",
      "4067/4067 [==============================] - 2s 429us/step - loss: 0.1495 - acc: 0.9363 - val_loss: 0.2725 - val_acc: 0.9179\n",
      "Epoch 17/59\n",
      "4067/4067 [==============================] - 2s 412us/step - loss: 0.1294 - acc: 0.9439 - val_loss: 0.2909 - val_acc: 0.9077\n",
      "Epoch 18/59\n",
      "4067/4067 [==============================] - 2s 417us/step - loss: 0.1539 - acc: 0.9378 - val_loss: 0.2716 - val_acc: 0.9109\n",
      "Epoch 19/59\n",
      "4067/4067 [==============================] - 2s 424us/step - loss: 0.1431 - acc: 0.9373 - val_loss: 0.3384 - val_acc: 0.9173\n",
      "Epoch 20/59\n",
      "4067/4067 [==============================] - 2s 447us/step - loss: 0.1407 - acc: 0.9390 - val_loss: 0.3228 - val_acc: 0.9160\n",
      "Epoch 21/59\n",
      "4067/4067 [==============================] - 2s 436us/step - loss: 0.1416 - acc: 0.9329 - val_loss: 0.3610 - val_acc: 0.8923\n",
      "Epoch 22/59\n",
      "4067/4067 [==============================] - 2s 457us/step - loss: 0.1274 - acc: 0.9489 - val_loss: 0.3253 - val_acc: 0.9192\n",
      "Epoch 23/59\n",
      "4067/4067 [==============================] - 2s 447us/step - loss: 0.1183 - acc: 0.9501 - val_loss: 0.2975 - val_acc: 0.9135\n",
      "Epoch 24/59\n",
      "4067/4067 [==============================] - 2s 434us/step - loss: 0.1357 - acc: 0.9432 - val_loss: 0.2616 - val_acc: 0.9218\n",
      "Epoch 25/59\n",
      "4067/4067 [==============================] - 2s 419us/step - loss: 0.1325 - acc: 0.9471 - val_loss: 0.3600 - val_acc: 0.9026\n",
      "Epoch 26/59\n",
      "4067/4067 [==============================] - 2s 427us/step - loss: 0.1318 - acc: 0.9457 - val_loss: 0.3595 - val_acc: 0.8955\n",
      "Epoch 27/59\n",
      "4067/4067 [==============================] - 2s 436us/step - loss: 0.1570 - acc: 0.9368 - val_loss: 0.3598 - val_acc: 0.8923\n",
      "Epoch 28/59\n",
      "4067/4067 [==============================] - 2s 422us/step - loss: 0.1253 - acc: 0.9484 - val_loss: 0.3379 - val_acc: 0.9006\n",
      "Epoch 29/59\n",
      "4067/4067 [==============================] - 2s 412us/step - loss: 0.1274 - acc: 0.9457 - val_loss: 0.3340 - val_acc: 0.9147\n",
      "Epoch 30/59\n",
      "4067/4067 [==============================] - 2s 420us/step - loss: 0.1058 - acc: 0.9555 - val_loss: 0.3280 - val_acc: 0.9212\n",
      "Epoch 31/59\n",
      "4067/4067 [==============================] - 2s 415us/step - loss: 0.1356 - acc: 0.9479 - val_loss: 0.2701 - val_acc: 0.9263\n",
      "Epoch 32/59\n",
      "4067/4067 [==============================] - 2s 417us/step - loss: 0.1217 - acc: 0.9511 - val_loss: 0.4524 - val_acc: 0.8897\n",
      "Epoch 33/59\n",
      "4067/4067 [==============================] - 2s 440us/step - loss: 0.1173 - acc: 0.9501 - val_loss: 0.3675 - val_acc: 0.8904\n",
      "Epoch 34/59\n",
      "4067/4067 [==============================] - 2s 420us/step - loss: 0.1057 - acc: 0.9575 - val_loss: 0.4708 - val_acc: 0.8718\n",
      "Epoch 35/59\n",
      "4067/4067 [==============================] - 2s 411us/step - loss: 0.1195 - acc: 0.9464 - val_loss: 0.4662 - val_acc: 0.8853\n",
      "Epoch 36/59\n",
      "4067/4067 [==============================] - 2s 431us/step - loss: 0.1507 - acc: 0.9361 - val_loss: 0.5384 - val_acc: 0.8923\n",
      "Epoch 37/59\n",
      "4067/4067 [==============================] - 2s 403us/step - loss: 0.1281 - acc: 0.9484 - val_loss: 0.5009 - val_acc: 0.8981\n",
      "Epoch 38/59\n",
      "4067/4067 [==============================] - 2s 402us/step - loss: 0.1100 - acc: 0.9552 - val_loss: 0.5386 - val_acc: 0.9019\n",
      "Epoch 39/59\n",
      "4067/4067 [==============================] - 2s 392us/step - loss: 0.1115 - acc: 0.9523 - val_loss: 0.4056 - val_acc: 0.9128\n",
      "Epoch 40/59\n",
      "4067/4067 [==============================] - 2s 402us/step - loss: 0.0984 - acc: 0.9589 - val_loss: 0.5095 - val_acc: 0.9026\n",
      "Epoch 41/59\n",
      "4067/4067 [==============================] - 2s 415us/step - loss: 0.1013 - acc: 0.9567 - val_loss: 0.2972 - val_acc: 0.9006\n",
      "Epoch 42/59\n",
      "4067/4067 [==============================] - 2s 412us/step - loss: 0.1159 - acc: 0.9498 - val_loss: 0.5124 - val_acc: 0.9026\n",
      "Epoch 43/59\n",
      "4067/4067 [==============================] - 2s 416us/step - loss: 0.1022 - acc: 0.9557 - val_loss: 0.5227 - val_acc: 0.9026\n",
      "Epoch 44/59\n",
      "4067/4067 [==============================] - 2s 399us/step - loss: 0.0983 - acc: 0.9597 - val_loss: 0.4954 - val_acc: 0.8987\n",
      "Epoch 45/59\n",
      "4067/4067 [==============================] - 2s 426us/step - loss: 0.1254 - acc: 0.9479 - val_loss: 0.2917 - val_acc: 0.9199\n",
      "Epoch 46/59\n",
      "4067/4067 [==============================] - 2s 407us/step - loss: 0.1186 - acc: 0.9525 - val_loss: 0.2711 - val_acc: 0.9199\n",
      "Epoch 47/59\n",
      "4067/4067 [==============================] - 2s 394us/step - loss: 0.0978 - acc: 0.9604 - val_loss: 0.3164 - val_acc: 0.9269\n",
      "Epoch 48/59\n",
      "4067/4067 [==============================] - 2s 396us/step - loss: 0.0956 - acc: 0.9594 - val_loss: 0.3670 - val_acc: 0.9186\n",
      "Epoch 49/59\n",
      "4067/4067 [==============================] - 2s 428us/step - loss: 0.0930 - acc: 0.9614 - val_loss: 0.3123 - val_acc: 0.9224\n",
      "Epoch 50/59\n",
      "4067/4067 [==============================] - 2s 410us/step - loss: 0.1012 - acc: 0.9582 - val_loss: 0.2761 - val_acc: 0.9179\n",
      "Epoch 51/59\n",
      "4067/4067 [==============================] - 2s 406us/step - loss: 0.1213 - acc: 0.9496 - val_loss: 0.4582 - val_acc: 0.8821\n",
      "Epoch 52/59\n",
      "4067/4067 [==============================] - 2s 425us/step - loss: 0.0881 - acc: 0.9658 - val_loss: 0.3291 - val_acc: 0.9141\n",
      "Epoch 53/59\n",
      "4067/4067 [==============================] - 2s 415us/step - loss: 0.1036 - acc: 0.9533 - val_loss: 0.3199 - val_acc: 0.9167\n",
      "Epoch 54/59\n",
      "4067/4067 [==============================] - 2s 419us/step - loss: 0.0873 - acc: 0.9639 - val_loss: 0.2934 - val_acc: 0.9154\n",
      "Epoch 55/59\n",
      "4067/4067 [==============================] - 2s 410us/step - loss: 0.0863 - acc: 0.9636 - val_loss: 0.3316 - val_acc: 0.9154\n",
      "Epoch 56/59\n",
      "4067/4067 [==============================] - 2s 400us/step - loss: 0.0863 - acc: 0.9597 - val_loss: 0.4001 - val_acc: 0.9179\n",
      "Epoch 57/59\n",
      "4067/4067 [==============================] - 2s 411us/step - loss: 0.0892 - acc: 0.9648 - val_loss: 0.3249 - val_acc: 0.9231\n",
      "Epoch 58/59\n",
      "4067/4067 [==============================] - 2s 410us/step - loss: 0.0854 - acc: 0.9651 - val_loss: 0.4786 - val_acc: 0.9058\n",
      "Epoch 59/59\n",
      "4067/4067 [==============================] - 2s 399us/step - loss: 0.1172 - acc: 0.9557 - val_loss: 0.2501 - val_acc: 0.9269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7054309b70>"
      ]
     },
     "execution_count": 92,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_model = Sequential()\n",
    "static_model.add(Conv1D(filters=32, kernel_size=7, activation='relu',kernel_initializer='he_uniform',input_shape=(timesteps, input_dim)))\n",
    "static_model.add(BatchNormalization()) \n",
    "static_model.add(Dropout(0.0))\n",
    "static_model.add(Conv1D(filters=32, kernel_size=1, activation='relu',kernel_initializer='he_uniform'))\n",
    "static_model.add(BatchNormalization())\n",
    "static_model.add(Dropout(0.2))\n",
    "static_model.add(Conv1D(filters=32, kernel_size=7, activation='relu',kernel_initializer='he_uniform'))\n",
    "static_model.add(MaxPooling1D(pool_size=2))\n",
    "static_model.add(Flatten())\n",
    "static_model.add(Dense(32,activation='relu'))\n",
    "static_model.add(Dense(3, activation='softmax'))\n",
    "static_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy']) \n",
    "static_model.fit(X_train_static,Y_train_static, epochs=59, batch_size=32,\n",
    "                 validation_data=(X_test_static, Y_test_static), verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ztuderamtGG4",
    "outputId": "160e7ad3-c9aa-4d37-bbf7-32e10932c948"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.25014383807258894\n",
      "Test accuracy: 92.6923076923077\n"
     ]
    }
   ],
   "source": [
    "static_model_score = static_model.evaluate(X_test_static,Y_test_static,verbose=0)\n",
    "print('Test loss:', static_model_score[0])\n",
    "print('Test accuracy:', static_model_score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "colab_type": "code",
    "id": "ESbYZ5sYh6KD",
    "outputId": "091f3c7b-bd8f-4299-d48e-0583996568ef"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi0AAAIqCAYAAADo7HrKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIiekKQlIiIiekKSloiIiOgJ/wMsvbKZTWjtfAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "predict_static = dynamic_model.predict(X_test_static)\n",
    "f_predict_static = np.argmax(predict_static,axis=1)\n",
    "cm = confusion_matrix(np.argmax(Y_test_static,axis=1), f_predict_static)\n",
    "plt.figure(figsize=(8,8))\n",
    "labels=['SITTING','STANDING','LAYING']\n",
    "plot_confusion_matrix(cm, classes=labels, \n",
    "                      normalize=True, title='Static Model confusion matrix', cmap = plt.cm.Greens)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s9Z3rdD8wkRw"
   },
   "source": [
    "Based on above confusion matrix results the class sitting and standing labels more confuse to predict  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TE0gy4xn6D4U"
   },
   "outputs": [],
   "source": [
    "static_model.save('gdrive/My Drive/HAR/final_static_model.m2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FCAMjBSTYhs1"
   },
   "source": [
    "<h3>Dynamic model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "Y_Fzg5zX45tE",
    "outputId": "0afb0aeb-f844-47d6-e688-2b340cfc271b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:51: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "# Data directory\n",
    "DATADIR = 'gdrive/My Drive/HAR/UCI_HAR_Dataset'\n",
    "\n",
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]\n",
    "\n",
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'gdrive/My Drive/HAR/UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))\n",
    "\n",
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'gdrive/My Drive/HAR/UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "    y_subset = y <= 3 #taking y_class labels less than 3 \n",
    "    y = y[y_subset]\n",
    "    return pd.get_dummies(y).as_matrix(),y_subset\n",
    "\n",
    "def load_dynamic_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_train_sub  = load_y('train') \n",
    "    y_test,y_test_sub = load_y('test')\n",
    "    X_train = X_train[y_train_sub]\n",
    "    X_test = X_test[y_test_sub]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "  \n",
    "# Loading the train and test data\n",
    "X_train_dynamic, X_test_dynamic, Y_train_dynamic, Y_test_dynamic = load_dynamic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "icO1YtaI45yf",
    "outputId": "e6c41875-4be0-4b25-c3f7-dab7c6cada34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3285, 128, 9) (3285, 3)\n",
      "(1387, 128, 9) (1387, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_dynamic.shape,Y_train_dynamic.shape)\n",
    "print(X_test_dynamic.shape,Y_test_dynamic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "7uoOxtmO1e2v",
    "outputId": "644d578e-ec63-4fb3-9565-8d264adfa280"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.954642 using {'kernel_size2': 7, 'kernel_size': 1, 'filters2': 32, 'filters': 32, 'dropout_rate2': 0.2, 'dropout_rate': 0.0}\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "import keras.utils\n",
    "from keras import utils as np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "def create_model(filters=1,filters2=1,kernel_size2=1,kernel_size=1,dropout_rate2=0.0,dropout_rate=0.0):\n",
    "  model = Sequential()\n",
    "  model.add(keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, activation='relu',kernel_initializer='he_uniform',input_shape=(timesteps, input_dim)))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dropout(dropout_rate))\n",
    "  model.add(keras.layers.Conv1D(filters=filters2, kernel_size=kernel_size2, activation='relu',kernel_initializer='he_uniform'))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dropout(dropout_rate2))\n",
    "  model.add(MaxPooling1D(pool_size=2))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(3, activation='softmax'))\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy']) \n",
    "  return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "model = KerasClassifier(build_fn=create_model, epochs=30, batch_size=16, verbose=0)\n",
    "# define the grid search parameters\n",
    "filters = [1,32,64]\n",
    "filters2 = [1,32,64]\n",
    "kernel_size = [1,3,5,7]\n",
    "kernel_size2 = [1,3,5,7]\n",
    "dropout_rate = [0.0,0.2,0.4,0.6,0.8]\n",
    "dropout_rate2 = [0.0,0.2,0.4,0.6,0.8]\n",
    "param = dict(filters=filters,kernel_size=kernel_size,dropout_rate=dropout_rate,filters2=filters2,dropout_rate2=dropout_rate2,kernel_size2=kernel_size2)\n",
    "random = RandomizedSearchCV(estimator=model,param_distributions=param,cv=3)\n",
    "rand_result = random.fit(X_train_dynamic, Y_train_dynamic)\n",
    "# summarize results \n",
    "print(\"Best: %f using %s\" % (rand_result.best_score_, rand_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "feN-RkWb456B",
    "outputId": "2590017f-d861-48e7-ec0b-f4b9d1b6aa8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_8 (Conv1D)            (None, 128, 32)           320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 128, 32)           128       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 122, 32)           7200      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 122, 32)           128       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 122, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 61, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1952)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 5859      \n",
      "=================================================================\n",
      "Total params: 13,635\n",
      "Trainable params: 13,507\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dynamic_model = Sequential()\n",
    "dynamic_model.add(Conv1D(filters=32, kernel_size=1, activation='relu',kernel_initializer='he_uniform',input_shape=(timesteps, input_dim)))\n",
    "dynamic_model.add(BatchNormalization()) \n",
    "dynamic_model.add(Dropout(0.0))\n",
    "dynamic_model.add(Conv1D(filters=32, kernel_size=7, activation='relu',kernel_initializer='he_uniform'))\n",
    "dynamic_model.add(BatchNormalization())\n",
    "dynamic_model.add(Dropout(0.2))\n",
    "dynamic_model.add(MaxPooling1D(pool_size=2))\n",
    "dynamic_model.add(Flatten())\n",
    "dynamic_model.add(Dense(3, activation='softmax'))\n",
    "dynamic_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nACEkhW345_d",
    "outputId": "07e72ec2-597a-4a91-cbcc-ecaadedfa4fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3285 samples, validate on 1387 samples\n",
      "Epoch 1/30\n",
      "3285/3285 [==============================] - 2s 722us/step - loss: 0.6781 - acc: 0.7367 - val_loss: 0.4249 - val_acc: 0.8717\n",
      "Epoch 2/30\n",
      "3285/3285 [==============================] - 1s 342us/step - loss: 0.1024 - acc: 0.9650 - val_loss: 0.2290 - val_acc: 0.9229\n",
      "Epoch 3/30\n",
      "3285/3285 [==============================] - 1s 347us/step - loss: 0.0371 - acc: 0.9924 - val_loss: 0.1777 - val_acc: 0.9430\n",
      "Epoch 4/30\n",
      "3285/3285 [==============================] - 1s 353us/step - loss: 0.0223 - acc: 0.9948 - val_loss: 0.1433 - val_acc: 0.9560\n",
      "Epoch 5/30\n",
      "3285/3285 [==============================] - 1s 344us/step - loss: 0.0124 - acc: 0.9973 - val_loss: 0.1282 - val_acc: 0.9589\n",
      "Epoch 6/30\n",
      "3285/3285 [==============================] - 1s 347us/step - loss: 0.0138 - acc: 0.9973 - val_loss: 0.1320 - val_acc: 0.9553\n",
      "Epoch 7/30\n",
      "3285/3285 [==============================] - 1s 342us/step - loss: 0.0061 - acc: 0.9991 - val_loss: 0.1366 - val_acc: 0.9618\n",
      "Epoch 8/30\n",
      "3285/3285 [==============================] - 1s 360us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.1017 - val_acc: 0.9632\n",
      "Epoch 9/30\n",
      "3285/3285 [==============================] - 1s 365us/step - loss: 0.0044 - acc: 0.9997 - val_loss: 0.0724 - val_acc: 0.9726\n",
      "Epoch 10/30\n",
      "3285/3285 [==============================] - 1s 352us/step - loss: 0.0031 - acc: 0.9994 - val_loss: 0.0766 - val_acc: 0.9740\n",
      "Epoch 11/30\n",
      "3285/3285 [==============================] - 1s 341us/step - loss: 0.0071 - acc: 0.9979 - val_loss: 0.1750 - val_acc: 0.9394\n",
      "Epoch 12/30\n",
      "3285/3285 [==============================] - 1s 353us/step - loss: 0.0091 - acc: 0.9967 - val_loss: 0.1148 - val_acc: 0.9589\n",
      "Epoch 13/30\n",
      "3285/3285 [==============================] - 1s 346us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0986 - val_acc: 0.9683\n",
      "Epoch 14/30\n",
      "3285/3285 [==============================] - 1s 359us/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0990 - val_acc: 0.9640\n",
      "Epoch 15/30\n",
      "3285/3285 [==============================] - 1s 366us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1133 - val_acc: 0.9618\n",
      "Epoch 16/30\n",
      "3285/3285 [==============================] - 1s 346us/step - loss: 0.0023 - acc: 0.9997 - val_loss: 0.0685 - val_acc: 0.9784\n",
      "Epoch 17/30\n",
      "3285/3285 [==============================] - 1s 351us/step - loss: 0.0019 - acc: 0.9997 - val_loss: 0.0845 - val_acc: 0.9704\n",
      "Epoch 18/30\n",
      "3285/3285 [==============================] - 1s 347us/step - loss: 6.9701e-04 - acc: 1.0000 - val_loss: 0.0715 - val_acc: 0.9755\n",
      "Epoch 19/30\n",
      "3285/3285 [==============================] - 1s 350us/step - loss: 6.2882e-04 - acc: 1.0000 - val_loss: 0.0593 - val_acc: 0.9784\n",
      "Epoch 20/30\n",
      "3285/3285 [==============================] - 1s 347us/step - loss: 8.1471e-04 - acc: 0.9997 - val_loss: 0.0672 - val_acc: 0.9748\n",
      "Epoch 21/30\n",
      "3285/3285 [==============================] - 1s 357us/step - loss: 6.5646e-04 - acc: 1.0000 - val_loss: 0.0700 - val_acc: 0.9719\n",
      "Epoch 22/30\n",
      "3285/3285 [==============================] - 1s 357us/step - loss: 4.3850e-04 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9740\n",
      "Epoch 23/30\n",
      "3285/3285 [==============================] - 1s 342us/step - loss: 0.0032 - acc: 0.9994 - val_loss: 0.1153 - val_acc: 0.9704\n",
      "Epoch 24/30\n",
      "3285/3285 [==============================] - 1s 391us/step - loss: 0.0052 - acc: 0.9982 - val_loss: 0.0806 - val_acc: 0.9697\n",
      "Epoch 25/30\n",
      "3285/3285 [==============================] - 1s 367us/step - loss: 0.0045 - acc: 0.9985 - val_loss: 0.1324 - val_acc: 0.9654\n",
      "Epoch 26/30\n",
      "3285/3285 [==============================] - 1s 363us/step - loss: 0.0099 - acc: 0.9967 - val_loss: 0.1710 - val_acc: 0.9632\n",
      "Epoch 27/30\n",
      "3285/3285 [==============================] - 1s 353us/step - loss: 0.0060 - acc: 0.9976 - val_loss: 0.0965 - val_acc: 0.9712\n",
      "Epoch 28/30\n",
      "3285/3285 [==============================] - 1s 353us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0491 - val_acc: 0.9827\n",
      "Epoch 29/30\n",
      "3285/3285 [==============================] - 1s 343us/step - loss: 4.6941e-04 - acc: 0.9997 - val_loss: 0.0625 - val_acc: 0.9798\n",
      "Epoch 30/30\n",
      "3285/3285 [==============================] - 1s 345us/step - loss: 1.9695e-04 - acc: 1.0000 - val_loss: 0.0615 - val_acc: 0.9820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7061785a90>"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy']) \n",
    "dynamic_model.fit(X_train_dynamic,Y_train_dynamic, epochs=30, batch_size=32,validation_data=(X_test_dynamic, Y_test_dynamic),verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "m7xL0fTa5PW3",
    "outputId": "f5366c53-defa-4fe8-d36c-0f0838c24d1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.06151885367722327\n",
      "Test accuracy: 98.19754866618601\n"
     ]
    }
   ],
   "source": [
    "dynamic_model_score = dynamic_model.evaluate(X_test_dynamic,Y_test_dynamic,verbose=0)\n",
    "print('Test loss:', dynamic_model_score[0])\n",
    "print('Test accuracy:', dynamic_model_score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "id": "pF0wvxUdfZzT",
    "outputId": "8ef252dd-df0d-4a99-80f0-bb76fa5dec30"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAIxCAYAAABaRiKwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "predict_dynamic = dynamic_model.predict(X_test_dynamic)\n",
    "f_predict_dynamic = np.argmax(predict_dynamic,axis=1)\n",
    "cm = confusion_matrix(np.argmax(Y_test_dynamic,axis=1), f_predict_dynamic)\n",
    "plt.figure(figsize=(8,8))\n",
    "labels=['WALKING','WALKING_UPSTAIRS','WALKING_DOWNSTAIRS']\n",
    "plot_confusion_matrix(cm, classes=labels, \n",
    "                      normalize=True, title='Dynamic model confusion matrix', cmap = plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tTH1xHg_wytt"
   },
   "source": [
    "In above confusion matrix results states that  98% of class labels are correctly predicted  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v74Q13KGDYsG"
   },
   "outputs": [],
   "source": [
    "dynamic_model.save('gdrive/My Drive/HAR/final_dynamic_model.m3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bZlLgMkzYptO"
   },
   "source": [
    "<h3>Normal model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "0CxmRPYL5aE-",
    "outputId": "25461835-36a1-4f82-dc80-027e665bc51c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "# Data directory\n",
    "DATADIR = 'gdrive/My Drive/HAR/UCI_HAR_Dataset'\n",
    "\n",
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]\n",
    "\n",
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'gdrive/My Drive/HAR/UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))\n",
    "\n",
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'gdrive/My Drive/HAR/UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "    return pd.get_dummies(y).as_matrix()\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train,y_test = load_y('train'), load_y('test') \n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "  \n",
    "# Loading the train and test data\n",
    "Q_X_train, Q_X_test, Q_Y_train, Q_Y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OetAfM1ry9mQ"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "b_model = load_model('gdrive/My Drive/HAR/final_binary_model.m1')\n",
    "s_model = load_model('gdrive/My Drive/HAR/final_static_model.m2')\n",
    "d_model = load_model('gdrive/My Drive/HAR/final_dynamic_model.m3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3yMFOqE-6YX6"
   },
   "outputs": [],
   "source": [
    "#predicting output activity\n",
    "def predict(X):\n",
    "    ##predicting whether dynamic or static\n",
    "    predict_binary = binary_model.predict(X)\n",
    "    f_predict_binary =  np.argmax(predict_binary, axis=1)\n",
    "    #static data filter\n",
    "    X_static = X[f_predict_binary==1]\n",
    "    #dynamic data filter\n",
    "    X_dynamic = X[f_predict_binary==0]\n",
    "    #predicting static activities\n",
    "    predict_static = static_model.predict(X_static)\n",
    "    f_predict_static = np.argmax(predict_static,axis=1)\n",
    "    #adding 3 because need to get inal prediction lable as output\n",
    "    f_predict_static = f_predict_static + 3 \n",
    "    #predicting dynamic activites\n",
    "    predict_dynamic = dynamic_model.predict(X_dynamic)\n",
    "    f_predict_dynamic = np.argmax(predict_dynamic,axis=1)\n",
    "    #adding 1 because need to get inal prediction lable as output\n",
    "    f_predict_dynamic = f_predict_dynamic \n",
    "    ##appending final output to one list in the same sequence of input data\n",
    "    i,j = 0,0 \n",
    "    final_predict = []\n",
    "    for q_p in f_predict_binary:\n",
    "        if q_p == 1:\n",
    "            final_predict.append(f_predict_static[i])\n",
    "            i = i + 1\n",
    "        else:\n",
    "            final_predict.append(f_predict_dynamic[j])\n",
    "            j = j + 1 \n",
    "    return final_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "WwRLX9zraO4s",
    "outputId": "31232aa6-5375-4459-aab7-e541b9c50e97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of train data 0.9802774755168662\n",
      "Accuracy of validation data 0.9460468272819816\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "train_pred = predict(Q_X_train)\n",
    "test_pred = predict(Q_X_test)\n",
    "print('Accuracy of train data',accuracy_score(np.argmax(Q_Y_train,axis=1),train_pred))\n",
    "print('Accuracy of validation data',accuracy_score(np.argmax(Q_Y_test,axis=1),test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "id": "bPmt3TOt-1cL",
    "outputId": "017df222-65b6-42da-f026-ccde97fd4c5e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAIxCAYAAABaRiKwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(np.argmax(Q_Y_test,axis=1), test_pred)\n",
    "plt.figure(figsize=(8,8))\n",
    "labels=['WALKING','WALKING_UPSTAIRS','WALKING_DOWNSTAIRS','SITTING','STANDING','LAYING']\n",
    "plot_confusion_matrix(cm, classes=labels, \n",
    "                      normalize=True, title='Normalized confusion matrix', cmap = plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "leSZ7hLjziRL",
    "outputId": "5f18b6be-58c6-487a-ded9-c56bca6f8e07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+----------+\n",
      "|           Model            | Accuracy |\n",
      "+----------------------------+----------+\n",
      "|      LSTM BASE MODEL       |   91%    |\n",
      "|       LSTM 2 Layer         |   93%    |\n",
      "|       Static model         |   92%    |\n",
      "|       Dynamic model        |   98%    |\n",
      "| Binary + static + dynamic  |   94%    |\n",
      "+----------------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"Model\", \"Accuracy\"]\n",
    "x.add_row([\"LSTM BASE MODEL \",  '91%'])\n",
    "x.add_row([\"LSTM 2 Layer \", '93%'])\n",
    "x.add_row([\"Static model \", '92%'])\n",
    "x.add_row([\"Dynamic model \", '98%'])\n",
    "x.add_row([\"Binary + static + dynamic \", '94%'])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RXjj9Dscimdh"
   },
   "source": [
    "<h3>Observations</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3RpeLU1jirBQ"
   },
   "source": [
    "<ol>\n",
    "<li>In this dataset about Human activity Recoginition using smart phones data, Various LSTM and CNN deep learning techniques are applied </li>\n",
    "<li>We got the results by using LSTM we got 93% accuracy  </li>\n",
    "<li>By applying the new concept called Divide and conquer we dividede te data into two parts </li>\n",
    "<li>Applied first 3 class labels as one model and remaining 3 class labels as another model and predicted individually </li>\n",
    "<li>first 3 class label models called dynamic models and last 3 class labels called as static models </li>\n",
    "<li>Applied as 2 models and we got Static model as 92% accuracy and dynamic model as 98% accuracy </li>\n",
    "<li>In static model there is a lot of confusion between standing and sitting class labels because of that confusion it gives lower accuracy </li>\n",
    "<li>But in dynamic models it gives excellent classification it gaves 98% accuracy </li>\n",
    "<li>Overall by combing all these  6 labels we got 94% as final accuracy by using  concept called divde and conquer </li>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5LtxraSC1Eaj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HAR_LSTM&DAQ.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
